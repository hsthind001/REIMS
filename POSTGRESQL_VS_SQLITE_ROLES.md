# PostgreSQL vs SQLite - Roles and Responsibilities in REIMS

## üéØ What Each Database Is SUPPOSED To Do

### PostgreSQL (Enterprise Database Server)

**Type:** Client-Server Database
**Location:** Docker container `reims-postgres`
**Port:** 5432

#### Intended Responsibilities:

1. **Primary Data Storage** (Production)
   - Store all document metadata
   - Manage user accounts and permissions
   - Track file processing status
   - Store analytics and metrics

2. **Concurrent Access**
   - Handle multiple users simultaneously
   - Process 100+ requests per second
   - Manage database connections efficiently
   - Transaction isolation for data consistency

3. **Advanced Features**
   ```sql
   -- Complex queries
   SELECT p.name, COUNT(fd.id) as doc_count,
          AVG(fd.file_size) as avg_size
   FROM properties p
   LEFT JOIN financial_documents fd ON fd.property_id = p.id
   GROUP BY p.name
   HAVING COUNT(fd.id) > 10;
   
   -- Full-text search
   SELECT * FROM documents 
   WHERE to_tsvector('english', content) @@ to_tsquery('real estate');
   
   -- Window functions
   SELECT *, 
          ROW_NUMBER() OVER (PARTITION BY property_id ORDER BY upload_date DESC)
   FROM financial_documents;
   ```

4. **Data Integrity**
   - Foreign key constraints
   - Triggers for automatic updates
   - Row-level security
   - ACID compliance

5. **Scalability**
   - Replication (master-slave)
   - Partitioning large tables
   - Connection pooling
   - Backup and recovery

#### PostgreSQL Code Configuration:

**File: `backend/db/connection.py`**
```python
# Async PostgreSQL connection pool
class DatabaseConfig:
    HOST = 'localhost'
    PORT = 5432
    DATABASE = 'reims'
    USER = 'postgres'
    PASSWORD = 'dev123'
    MIN_POOL_SIZE = 10  # Keep 10 connections ready
    MAX_POOL_SIZE = 20  # Allow up to 20 concurrent connections

async def init_db():
    """Create connection pool for PostgreSQL"""
    global _connection_pool
    _connection_pool = await asyncpg.create_pool(
        host=DatabaseConfig.HOST,
        port=DatabaseConfig.PORT,
        database=DatabaseConfig.DATABASE,
        user=DatabaseConfig.USER,
        password=DatabaseConfig.PASSWORD,
        min_size=DatabaseConfig.MIN_POOL_SIZE,
        max_size=DatabaseConfig.MAX_POOL_SIZE
    )
```

**File: `docker-compose.yml`**
```yaml
postgres:
  image: postgres:16
  container_name: reims-postgres
  environment:
    POSTGRES_DB: reims
    POSTGRES_USER: postgres
    POSTGRES_PASSWORD: dev123
  ports:
    - "5432:5432"
  volumes:
    - postgres-data:/var/lib/postgresql/data
```

---

### SQLite (Embedded Database)

**Type:** File-based Database
**Location:** `C:\REIMS\reims.db`
**Size:** ~360 KB (grows with data)

#### Actual Responsibilities (Current):

1. **Development Database** (Actually doing production work!)
   - ‚úÖ Storing all 28 uploaded documents
   - ‚úÖ Managing document metadata
   - ‚úÖ Tracking upload status
   - ‚úÖ Storing user data

2. **Simple Operations**
   ```sql
   -- Single-user CRUD operations
   INSERT INTO financial_documents (id, file_name, status)
   VALUES ('uuid...', 'ESP 2024.pdf', 'queued');
   
   SELECT * FROM financial_documents 
   WHERE property_id = 'xxx' 
   ORDER BY upload_date DESC;
   
   UPDATE financial_documents 
   SET status = 'processed' 
   WHERE id = 'uuid...';
   ```

3. **File-Based Storage**
   - No server required
   - Direct file access
   - Single database file
   - Local transactions

4. **Performance Optimizations**
   ```python
   # WAL mode for better concurrency
   PRAGMA journal_mode=WAL;
   
   # Fast synchronization
   PRAGMA synchronous=NORMAL;
   
   # Memory caching
   PRAGMA cache_size=10000;
   
   # Memory-based temp storage
   PRAGMA temp_store=MEMORY;
   ```

#### SQLite Code Configuration:

**File: `backend/api/database.py`**
```python
from dotenv import load_dotenv
load_dotenv()

# Try to get DATABASE_URL from environment
DATABASE_URL = os.getenv(
    "DATABASE_URL",
    "postgresql://postgres:dev123@localhost:5432/reims"  # Default
)

# Try PostgreSQL first
try:
    if DATABASE_URL.startswith("postgresql://"):
        engine = create_engine(DATABASE_URL)
        with engine.connect():
            pass
        print("Connected to PostgreSQL")  # Never prints!
    else:
        engine = create_engine(
            DATABASE_URL,
            connect_args={"check_same_thread": False}
        )
        print("Using SQLite database")
        
except Exception as e:
    # PostgreSQL connection fails, fallback to SQLite
    print(f"Database connection failed: {e}")
    print("Falling back to SQLite...")
    DATABASE_URL = "sqlite:///./reims.db"
    engine = create_engine(
        DATABASE_URL,
        connect_args={"check_same_thread": False}
    )
```

**File: `backend/database_optimized.py`**
```python
DATABASE_URL = "sqlite:///./reims.db"

# SQLite optimizations
SQLITE_PRAGMAS = {
    "journal_mode": "WAL",       # Write-Ahead Logging
    "synchronous": "NORMAL",     # Faster writes
    "cache_size": 10000,         # 10MB cache
    "temp_store": "MEMORY",      # In-memory temp tables
    "mmap_size": 268435456,      # 256MB memory-mapped
}
```

---

## üîÑ Current vs Intended Usage

| Feature | PostgreSQL (Intended) | SQLite (Actual) |
|---------|----------------------|-----------------|
| **Connection** | ‚ùå Should be active | ‚úÖ Is active |
| **Document Storage** | ‚ùå Should store 28 docs | ‚úÖ Stores 28 docs |
| **Upload Metadata** | ‚ùå Should track uploads | ‚úÖ Tracks uploads |
| **User Management** | ‚ùå Should manage users | ‚úÖ Manages users |
| **Query Performance** | ‚è© Fast (server optimized) | üêå Slower (file-based) |
| **Concurrent Users** | ‚úÖ 100+ users | ‚ö†Ô∏è 1-5 users max |
| **Scalability** | ‚úÖ Excellent | ‚ö†Ô∏è Limited |
| **Production Ready** | ‚úÖ Yes | ‚ö†Ô∏è For dev only |

---

## üìä What's In Each Database RIGHT NOW

### PostgreSQL (Docker Container)

**Status:** Running but EMPTY

```sql
-- All tables exist but have 0 records:
reims=# SELECT COUNT(*) FROM documents;
 count 
-------
     0

reims=# SELECT COUNT(*) FROM financial_documents;
 count 
-------
     0

reims=# SELECT COUNT(*) FROM properties;
 count 
-------
     5  -- Only test data
```

**Schema (Ready but unused):**
```
Tables created:
‚úÖ documents
‚úÖ financial_documents (with upload columns we added!)
‚úÖ properties
‚úÖ users
‚úÖ processing_jobs
‚úÖ extracted_data
‚úÖ tenants
‚úÖ leases

Status: All empty except test properties
```

### SQLite (Local File)

**Status:** ACTIVE and FULL

```sql
-- Your actual data:
sqlite> SELECT COUNT(*) FROM financial_documents;
28  -- All your uploads!

sqlite> SELECT file_name, status FROM financial_documents LIMIT 3;
ESP 2024 Income Statement.pdf|queued
ESP 2024 Cash Flow Statement.pdf|queued
ESP 2024 Balance Sheet.pdf|queued

sqlite> SELECT COUNT(*) FROM properties;
127  -- All property data

sqlite> SELECT COUNT(*) FROM users;
3  -- User accounts
```

**Tables (All populated):**
```
‚úÖ documents (legacy)
‚úÖ financial_documents (28 records - YOUR UPLOADS!)
‚úÖ properties (127 records)
‚úÖ users (3 accounts)
‚úÖ processing_jobs (queue data)
‚úÖ extracted_data (processed documents)
‚úÖ financial_transactions
‚úÖ property_documents
... 27 tables total
```

---

## üîç How to See What Each Database Is Doing

### Check PostgreSQL (Should have data, doesn't)

```powershell
# Via Docker
$env:PGPASSWORD = "dev123"
docker exec -i reims-postgres psql -U postgres -d reims -c `
  "SELECT COUNT(*) FROM financial_documents;"
# Result: 0

# Via Python (fails to connect!)
python -c "from sqlalchemy import create_engine; engine = create_engine('postgresql://postgres:dev123@localhost:5432/reims'); conn = engine.connect(); print('Connected!')"
# Result: ERROR - password authentication failed
```

### Check SQLite (Has all the data)

```powershell
# Via Python script
python show_my_uploads.py
# Result: Shows all 28 documents

# Via direct query
python -c "import sqlite3; conn = sqlite3.connect('reims.db'); print(f'Documents: {conn.execute(\"SELECT COUNT(*) FROM financial_documents\").fetchone()[0]}'); conn.close()"
# Result: Documents: 28

# Via API
curl http://localhost:8001/api/documents
# Result: Returns all 28 documents from SQLite
```

---

## üí° Why This Matters

### Current Impact (Using SQLite)

**Advantages:**
- ‚úÖ Everything works
- ‚úÖ No configuration needed
- ‚úÖ Fast for single user
- ‚úÖ Simple to backup (just copy the file)

**Limitations:**
- ‚ö†Ô∏è Can't handle many concurrent users
- ‚ö†Ô∏è Limited query performance on large datasets
- ‚ö†Ô∏è No built-in replication
- ‚ö†Ô∏è File locking issues with multiple processes

### If PostgreSQL Was Working

**Advantages:**
- ‚úÖ Handle 100+ concurrent users
- ‚úÖ Advanced queries run faster
- ‚úÖ Built-in backup/replication
- ‚úÖ Better security (row-level)
- ‚úÖ Production-grade reliability

**Trade-offs:**
- ‚ö†Ô∏è More complex setup
- ‚ö†Ô∏è Requires server management
- ‚ö†Ô∏è Higher resource usage
- ‚ö†Ô∏è Need proper authentication

---

## üéØ Bottom Line

### PostgreSQL (Enterprise Database Server)
**What it SHOULD do:**
- Store all production data
- Handle multiple users
- Provide advanced analytics
- Scale to millions of records

**What it's ACTUALLY doing:**
- ‚ùå Nothing (connection fails)
- ‚ùå Sitting empty in Docker
- ‚ùå Not receiving any data

### SQLite (Simple File Database)
**What it SHOULD do:**
- Development and testing
- Temporary data storage
- Simple applications

**What it's ACTUALLY doing:**
- ‚úÖ Storing ALL your uploads (28 docs)
- ‚úÖ Running the entire application
- ‚úÖ Handling all database operations
- ‚úÖ Working perfectly!

**The Reality:**
Your REIMS application is running on SQLite (development database) instead of PostgreSQL (production database), but everything is working fine for development purposes!

